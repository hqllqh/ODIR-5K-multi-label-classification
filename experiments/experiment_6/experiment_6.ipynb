{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/serdna1/ODIR-5K-multi-label-classification/blob/main/experiments/experiment_6/experiment_6.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download GitHub repository and data\n",
    "The repo wont be downloading in my local machine, since i already have it there. It will if someone is running this notebook on their own machine, colab, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "images_path = 'ODIR-5K-multi-label-classification/data/images/'\n",
    "\n",
    "# If the experiments folder doesnt exist im not in my local machine\n",
    "if not os.path.exists('../../experiments'):\n",
    "    # Clone project repository\n",
    "    !git clone https://github.com/serdna1/ODIR-5K-multi-label-classification.git\n",
    "\n",
    "    # Unzip images\n",
    "    with zipfile.ZipFile(f'{images_path}/train_fov_cc_fov_224.zip', 'r') as zip_ref:\n",
    "      print(\"Unzipping training images...\")\n",
    "      zip_ref.extractall(f'{images_path}/train_fov_cc_fov_224')\n",
    "    !rm ODIR-5K-multi-label-classification/data/images/train_fov_cc_fov_224.zip\n",
    "    !rm ODIR-5K-multi-label-classification/data/images/train_224.zip\n",
    "\n",
    "    # Move to the experiment folder\n",
    "    %cd ODIR-5K-multi-label-classification/experiments/experiment_6/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop some special patients from the dataset\n",
    "The background of some images is quite different from the rest ones. Therefore they wont be used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "images_path = '../../data/images/train_fov_cc_fov_224'\n",
    "\n",
    "special_images = ['2174_right.jpg', '2175_left.jpg', '2176_left.jpg', '2177_left.jpg',\n",
    "                  '2177_right.jpg', '2178_right.jpg', '2179_left.jpg', '2179_right.jpg',\n",
    "                  '2180_left.jpg', '2180_right.jpg', '2181_left.jpg', '2181_right.jpg',\n",
    "                  '2182_left.jpg', '2182_right.jpg', '2957_left.jpg', '2957_right.jpg']\n",
    "\n",
    "# Show one of this special images\n",
    "image_path = f'{images_path}/{special_images[7]}'\n",
    "img = Image.open(image_path)\n",
    "plt.imshow(img)\n",
    "plt.axis(False)\n",
    "plt.title('Example of special image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "original_annotations_path = '../../data/annotations/annotations.xlsx'\n",
    "annotations_path = 'data/annotations.xlsx'\n",
    "\n",
    "odir_df = pd.read_excel(original_annotations_path)\n",
    "\n",
    "patients_to_drop_df = odir_df[odir_df['Left-Fundus'].isin(special_images) | odir_df['Right-Fundus'].isin(special_images)]\n",
    "patients_to_drop_df # This are all the patients with one ore more of this spetial images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "experiment_data_path = 'data/'\n",
    "\n",
    "print(f'Annotations length before droping the rows with the special images: {len(odir_df)}')\n",
    "\n",
    "odir_df = odir_df.drop(patients_to_drop_df.index) # Drop the special patients\n",
    "Path(experiment_data_path).mkdir(parents=True, exist_ok=True) # Create the experiment data folder\n",
    "odir_df.to_excel(annotations_path) # Save annotations without the special patients\n",
    "\n",
    "print(f'Annotations length after droping the rows with the special images: {len(odir_df)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check dataset label distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = ['N','D','G','C','A','H','M','O']\n",
    "\n",
    "total_label_list = []\n",
    "for label in label_names:\n",
    "    total_label = int(odir_df.loc[:, [label]].sum())\n",
    "    total_label_list.append(total_label)\n",
    "\n",
    "plt.figure(figsize=(16,4))\n",
    "\n",
    "bar = plt.bar(label_names, total_label_list)\n",
    "\n",
    "for rect in bar:\n",
    "    height = rect.get_height()\n",
    "    plt.text(rect.get_x() + rect.get_width() / 2.0, height, f'{height:.0f}', ha='center', va='bottom')\n",
    "\n",
    "plt.xlabel(f'Label')\n",
    "plt.ylabel(f'No. of images')\n",
    "plt.title(f'Label distribution')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split dataset into train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../../scripts/')\n",
    "from utils import split_annotations\n",
    "os.chdir('../experiments/experiment_6/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the original annotations file into train and validation annotations files\n",
    "# val_ratio = 0.2 (value by default)\n",
    "split_annotations(annotations_path, experiment_data_path, test_split=False)\n",
    "\n",
    "# Read the previous three created .xlsx files into dataframes\n",
    "train_df = pd.read_excel(f'{experiment_data_path}/train_annotations.xlsx')\n",
    "val_df = pd.read_excel(f'{experiment_data_path}/val_annotations.xlsx')\n",
    "\n",
    "len(train_df), len(val_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check train and validation datasets label distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, label in enumerate(label_names):\n",
    "    plt.figure(figsize=(4,4))\n",
    "\n",
    "    total_label_train = int(train_df.loc[:, [label]].sum())\n",
    "    total_label_val = int(val_df.loc[:, [label]].sum())\n",
    "\n",
    "    bar = plt.bar(['Train', 'Val'], [total_label_train, total_label_val])\n",
    "\n",
    "    for rect in bar:\n",
    "        height = rect.get_height()\n",
    "        plt.text(rect.get_x() + rect.get_width() / 2.0, height, f'{height:.0f}', ha='center', va='bottom')\n",
    "\n",
    "    plt.xlabel(f'Dataset')\n",
    "    plt.ylabel(f'No. of images with label {label}')\n",
    "    plt.title(f'Distribution of label {label} by dataset')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../../scripts/train.py -h # Run this line to check the train script arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arguments that will be passed to the train script\n",
    "model_name = 'resnet50_dual_v2'\n",
    "images_path = '../../data/images/train_fov_cc_fov_224'\n",
    "train_annotations_path = 'data/train_annotations.xlsx'\n",
    "val_annotations_path = 'data/val_annotations.xlsx'\n",
    "lr = 0.05\n",
    "lr_scheduler = 'LinearLR'\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "patience = 20\n",
    "experiment_name = 'experiment_6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Created new resnet50_dual_v1 model.\n",
      "[INFO] Created SummaryWriter, saving to: ..\\runs\\resnet50_dual_v1\\experiment_5...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "906c0f50a00e4cc98e0b65caf3d34477",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep: 0 | t_loss: 0.6268 | t_kappa: 0.0024 | t_f1: 0.2445 | t_auc: 0.4950 | t_final: 0.2473 | v_loss: 0.5463 | v_kappa: 0.0000 | v_f1: 0.0000 | v_auc: 0.5368 | v_final: 0.1789\n",
      "Validation loss decreased (inf --> 0.546344).  Saving model ...\n",
      "Ep: 1 | t_loss: 0.4204 | t_kappa: 0.0000 | t_f1: 0.0000 | t_auc: 0.5961 | t_final: 0.1987 | v_loss: 0.4323 | v_kappa: 0.0000 | v_f1: 0.0000 | v_auc: 0.5235 | v_final: 0.1745\n",
      "Validation loss decreased (0.546344 --> 0.432265).  Saving model ...\n",
      "Ep: 2 | t_loss: 0.3582 | t_kappa: 0.0000 | t_f1: 0.0000 | t_auc: 0.6826 | t_final: 0.2275 | v_loss: 0.3806 | v_kappa: 0.0000 | v_f1: 0.0000 | v_auc: 0.5357 | v_final: 0.1786\n",
      "Validation loss decreased (0.432265 --> 0.380577).  Saving model ...\n",
      "Ep: 3 | t_loss: 0.3731 | t_kappa: 0.0000 | t_f1: 0.0000 | t_auc: 0.7861 | t_final: 0.2620 | v_loss: 0.3752 | v_kappa: 0.0000 | v_f1: 0.0000 | v_auc: 0.5720 | v_final: 0.1907\n",
      "Validation loss decreased (0.380577 --> 0.375194).  Saving model ...\n",
      "Ep: 4 | t_loss: 0.3236 | t_kappa: 0.0000 | t_f1: 0.0000 | t_auc: 0.7890 | t_final: 0.2630 | v_loss: 0.3632 | v_kappa: 0.0000 | v_f1: 0.0000 | v_auc: 0.6159 | v_final: 0.2053\n",
      "Validation loss decreased (0.375194 --> 0.363176).  Saving model ...\n",
      "Ep: 5 | t_loss: 0.3620 | t_kappa: 0.0701 | t_f1: 0.1658 | t_auc: 0.8407 | t_final: 0.3589 | v_loss: 0.3630 | v_kappa: 0.0000 | v_f1: 0.0000 | v_auc: 0.6429 | v_final: 0.2143\n",
      "Validation loss decreased (0.363176 --> 0.362989).  Saving model ...\n",
      "Ep: 6 | t_loss: 0.3150 | t_kappa: 0.0862 | t_f1: 0.2122 | t_auc: 0.8908 | t_final: 0.3964 | v_loss: 0.3590 | v_kappa: -0.0082 | v_f1: 0.0000 | v_auc: 0.6682 | v_final: 0.2200\n",
      "Validation loss decreased (0.362989 --> 0.359002).  Saving model ...\n",
      "Ep: 7 | t_loss: 0.3573 | t_kappa: 0.0654 | t_f1: 0.1729 | t_auc: 0.9384 | t_final: 0.3922 | v_loss: 0.3663 | v_kappa: -0.0070 | v_f1: 0.0000 | v_auc: 0.6946 | v_final: 0.2292\n",
      "EarlyStopping counter: 1 out of 20\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mD:\\odir-5k-multi-label-classification\\scripts\\train.py:228\u001b[0m\n\u001b[0;32m    223\u001b[0m writer \u001b[39m=\u001b[39m create_writer(model_name \u001b[39m=\u001b[39m opt\u001b[39m.\u001b[39mmodel_name,\n\u001b[0;32m    224\u001b[0m                        experiment_name \u001b[39m=\u001b[39m opt\u001b[39m.\u001b[39mexperiment_name,\n\u001b[0;32m    225\u001b[0m                        extra \u001b[39m=\u001b[39m opt\u001b[39m.\u001b[39mextra)\n\u001b[0;32m    227\u001b[0m \u001b[39m# Start the training loop\u001b[39;00m\n\u001b[1;32m--> 228\u001b[0m _, results \u001b[39m=\u001b[39m train(model\u001b[39m=\u001b[39;49mmodel,\n\u001b[0;32m    229\u001b[0m                    train_dataloader\u001b[39m=\u001b[39;49mtrain_dataloader,\n\u001b[0;32m    230\u001b[0m                    val_dataloader\u001b[39m=\u001b[39;49mval_dataloader,\n\u001b[0;32m    231\u001b[0m                    loss_fn\u001b[39m=\u001b[39;49mloss_fn,\n\u001b[0;32m    232\u001b[0m                    optimizer\u001b[39m=\u001b[39;49moptimizer,\n\u001b[0;32m    233\u001b[0m                    scheduler\u001b[39m=\u001b[39;49mscheduler,\n\u001b[0;32m    234\u001b[0m                    epochs\u001b[39m=\u001b[39;49mopt\u001b[39m.\u001b[39;49mepochs,\n\u001b[0;32m    235\u001b[0m                    stopper\u001b[39m=\u001b[39;49mstopper,\n\u001b[0;32m    236\u001b[0m                    device\u001b[39m=\u001b[39;49mdevice,\n\u001b[0;32m    237\u001b[0m                    writer\u001b[39m=\u001b[39;49mwriter)\n\u001b[0;32m    239\u001b[0m \u001b[39m# Create a df for the train results and save it to file\u001b[39;00m\n\u001b[0;32m    240\u001b[0m train_results_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(results)\n",
      "File \u001b[1;32mD:\\odir-5k-multi-label-classification\\scripts\\engine.py:103\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_dataloader, val_dataloader, loss_fn, optimizer, scheduler, epochs, stopper, device, writer)\u001b[0m\n\u001b[0;32m     96\u001b[0m model\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     98\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(epochs)):\n\u001b[0;32m     99\u001b[0m     (train_loss,\n\u001b[0;32m    100\u001b[0m      train_kappa,\n\u001b[0;32m    101\u001b[0m      train_f1,\n\u001b[0;32m    102\u001b[0m      train_auc,\n\u001b[1;32m--> 103\u001b[0m      train_final_score) \u001b[39m=\u001b[39m train_step(model\u001b[39m=\u001b[39;49mmodel,\n\u001b[0;32m    104\u001b[0m                                      dataloader\u001b[39m=\u001b[39;49mtrain_dataloader,\n\u001b[0;32m    105\u001b[0m                                      loss_fn\u001b[39m=\u001b[39;49mloss_fn,\n\u001b[0;32m    106\u001b[0m                                      optimizer\u001b[39m=\u001b[39;49moptimizer,\n\u001b[0;32m    107\u001b[0m                                      device\u001b[39m=\u001b[39;49mdevice)\n\u001b[0;32m    108\u001b[0m     (val_loss,\n\u001b[0;32m    109\u001b[0m      val_kappa,\n\u001b[0;32m    110\u001b[0m      val_f1,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    116\u001b[0m                    loss_fn\u001b[39m=\u001b[39mloss_fn,\n\u001b[0;32m    117\u001b[0m                    device\u001b[39m=\u001b[39mdevice)\n\u001b[0;32m    119\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    120\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEp: \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m | \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    121\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt_loss: \u001b[39m\u001b[39m{\u001b[39;00mtrain_loss\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m | \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mv_final: \u001b[39m\u001b[39m{\u001b[39;00mval_final_score\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[0;32m    131\u001b[0m     )\n",
      "File \u001b[1;32mD:\\odir-5k-multi-label-classification\\scripts\\engine.py:25\u001b[0m, in \u001b[0;36mtrain_step\u001b[1;34m(model, dataloader, loss_fn, optimizer, device)\u001b[0m\n\u001b[0;32m     22\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(logits, y)\n\u001b[0;32m     23\u001b[0m train_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem() \n\u001b[1;32m---> 25\u001b[0m optimizer\u001b[39m.\u001b[39;49mzero_grad()\n\u001b[0;32m     27\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m     29\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\andres\\anaconda3\\envs\\odirenv\\lib\\site-packages\\torch\\optim\\optimizer.py:435\u001b[0m, in \u001b[0;36mOptimizer.zero_grad\u001b[1;34m(self, set_to_none)\u001b[0m\n\u001b[0;32m    431\u001b[0m     param_groups \u001b[39m=\u001b[39m [\n\u001b[0;32m    432\u001b[0m         update_group(g, ng) \u001b[39mfor\u001b[39;00m g, ng \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(groups, saved_groups)]\n\u001b[0;32m    433\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__setstate__({\u001b[39m'\u001b[39m\u001b[39mstate\u001b[39m\u001b[39m'\u001b[39m: state, \u001b[39m'\u001b[39m\u001b[39mparam_groups\u001b[39m\u001b[39m'\u001b[39m: param_groups})\n\u001b[1;32m--> 435\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mzero_grad\u001b[39m(\u001b[39mself\u001b[39m, set_to_none: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m    436\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Sets the gradients of all optimized :class:`torch.Tensor` s to zero.\u001b[39;00m\n\u001b[0;32m    437\u001b[0m \n\u001b[0;32m    438\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[39m            the step altogether).\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m    450\u001b[0m     foreach \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mforeach\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%run ../../scripts/train.py --model {model_name} --images_path {images_path} --train_annotations_path {train_annotations_path} --val_annotations_path {val_annotations_path}\\\n",
    "                            --batch_size {batch_size} --epochs {epochs} --patience {patience} --experiment_name {experiment_name} --use_normalization --lr {lr}\\\n",
    "                            --lr_scheduler {lr_scheduler} --num_workers 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the next cell to see the metrics trough the epochs using the tensorboard interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir ../runs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the model with the validation dataset\n",
    "Since there is no access to the test annotatations (only to the images) the test will be performed on the validation dataset, to be able to see some results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../../scripts/test.py -h # Run this line to check the test script arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_annotations_path = 'data/val_annotations.xlsx' # val annotations are used for test\n",
    "images_path = '../../data/images/train_fov_cc_fov_224'\n",
    "model_path = 'outputs/resnet50_dual_v2_experiment_6_model.pth'\n",
    "ground_truth_path = 'outputs/ground_truth.xlsx'\n",
    "probs_path = 'outputs/probs.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../../scripts/test.py --model_path {model_path} --model_name {model_name} --images_path {images_path} --test_annotations_path {test_annotations_path} --use_normalization\\\n",
    "                           --ground_truth_path {ground_truth_path} --probs_path {probs_path}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the ODIR_evaluation.py script on test (validation) dataset\n",
    "This is a file provided along with the data by the challenge. And its supposed to have an example on how to compute the kappa, f1, auc, and final score metrics but i dont think they are well computed here as they are always too good (as shown later, the cualitative results for test are much worst). As a result of this, i use my own version of this metrics (see the function compute_challenge_metrics on the metrics script). Either way i'll run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_path = 'outputs/ground_truth.xlsx'\n",
    "probs_path = 'outputs/probs.xlsx'\n",
    "probs_csv_path = 'outputs/probs.csv'\n",
    "\n",
    "probs_df = pd.read_excel(probs_path)\n",
    "probs_df.to_csv(probs_csv_path, index=False) # The ODIR_evaluation script asks the probs file to be in .csv format\n",
    "\n",
    "%run ../../scripts/ODIR_evaluation.py {ground_truth_path} {probs_csv_path}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cuantitative results\n",
    "The test script prints some results as can be seen in the output of the previous cell. Now, lets see some more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = ['N','D','G','C','A','H','M','O']\n",
    "\n",
    "ground_truth = pd.read_excel(ground_truth_path).loc[:, label_names].to_numpy()\n",
    "probs = pd.read_excel(probs_path).loc[:, label_names].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "os.chdir('../../scripts')\n",
    "from metrics import plot_confusion_matrices\n",
    "os.chdir('../experiments/experiment_6/')\n",
    "\n",
    "# Print test classification report\n",
    "print('Clasification report:')\n",
    "print(\n",
    "    metrics.classification_report(\n",
    "        ground_truth,\n",
    "        probs>0.5,\n",
    "        output_dict=False,\n",
    "        target_names=label_names,\n",
    "        zero_division=0\n",
    "    )\n",
    ")\n",
    "\n",
    "# Plot one confusion matrix for each label\n",
    "plot_confusion_matrices(ground_truth, probs, label_names)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cualitative results\n",
    "One patient with each disease (at least) is predicted. The original images are ploted along with their ground truth and predicted labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "os.chdir('../../scripts')\n",
    "from utils import load_model\n",
    "from predict import pred_and_plot_image\n",
    "os.chdir('../experiments/experiment_6/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(model_path, model_name)\n",
    "\n",
    "test_df = pd.read_excel(test_annotations_path)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can run the next cell multiple times to see different results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in label_names:\n",
    "    patient = test_df[test_df[label] == 1].sample(replace=True).reset_index(drop=True)\n",
    "    pred_and_plot_image(model=model,\n",
    "                        left_image_path=f'{images_path}/{patient.at[0, \"Left-Fundus\"]}',\n",
    "                        right_image_path=f'{images_path}/{patient.at[0, \"Right-Fundus\"]}',\n",
    "                        transform=transform,\n",
    "                        device=device,\n",
    "                        label_names=label_names,\n",
    "                        ground_truth=patient.loc[0, label_names].to_numpy())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zip the experiment data folder, the SummaryWriter folder and the experiment outputs\n",
    "This is necessary in order to be able to download this folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "\n",
    "# shutil.make_archive('experiment_data_compressed',\n",
    "#                     format=\"zip\",\n",
    "#                     root_dir='data/')\n",
    "\n",
    "# shutil.make_archive('runs_compressed',\n",
    "#                     format=\"zip\",\n",
    "#                     root_dir='../runs/')\n",
    "\n",
    "# shutil.make_archive('outputs_compressed',\n",
    "#                     format=\"zip\",\n",
    "#                     root_dir='outputs/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "odirenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
